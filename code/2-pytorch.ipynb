{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch处理MNIST示例\n",
    "Mac安装命令为：\n",
    "\n",
    "    pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data:', torch.Size([60000, 28, 28]))\n",
      "('train_labels:', torch.Size([60000]))\n",
      "('test_data:', torch.Size([10000, 28, 28]))\n",
      "Net(\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (4): ReLU()\n",
      "  )\n",
      ")\n",
      "epoch=1, batch=100 loss: 0.6037\n",
      "epoch=1, batch=200 loss: 0.2501\n",
      "epoch=1, batch=300 loss: 0.1904\n",
      "epoch=1, batch=400 loss: 0.1635\n",
      "epoch=1 accuracy=96.00%\n",
      "epoch=2, batch=100 loss: 0.1173\n",
      "epoch=2, batch=200 loss: 0.1123\n",
      "epoch=2, batch=300 loss: 0.0940\n",
      "epoch=2, batch=400 loss: 0.0963\n",
      "epoch=2 accuracy=97.00%\n",
      "epoch=3, batch=100 loss: 0.0665\n",
      "epoch=3, batch=200 loss: 0.0690\n",
      "epoch=3, batch=300 loss: 0.0673\n",
      "epoch=3, batch=400 loss: 0.0721\n",
      "epoch=3 accuracy=97.00%\n",
      "epoch=4, batch=100 loss: 0.0444\n",
      "epoch=4, batch=200 loss: 0.0447\n",
      "epoch=4, batch=300 loss: 0.0469\n",
      "epoch=4, batch=400 loss: 0.0497\n",
      "epoch=4 accuracy=97.00%\n",
      "epoch=5, batch=100 loss: 0.0334\n",
      "epoch=5, batch=200 loss: 0.0313\n",
      "epoch=5, batch=300 loss: 0.0356\n",
      "epoch=5, batch=400 loss: 0.0348\n",
      "epoch=5 accuracy=97.00%\n",
      "epoch=6, batch=100 loss: 0.0269\n",
      "epoch=6, batch=200 loss: 0.0227\n",
      "epoch=6, batch=300 loss: 0.0243\n",
      "epoch=6, batch=400 loss: 0.0294\n",
      "epoch=6 accuracy=97.00%\n",
      "epoch=7, batch=100 loss: 0.0202\n",
      "epoch=7, batch=200 loss: 0.0172\n",
      "epoch=7, batch=300 loss: 0.0204\n",
      "epoch=7, batch=400 loss: 0.0216\n",
      "epoch=7 accuracy=97.00%\n",
      "epoch=8, batch=100 loss: 0.0160\n",
      "epoch=8, batch=200 loss: 0.0160\n",
      "epoch=8, batch=300 loss: 0.0171\n",
      "epoch=8, batch=400 loss: 0.0199\n",
      "epoch=8 accuracy=97.00%\n",
      "epoch=9, batch=100 loss: 0.0124\n",
      "epoch=9, batch=200 loss: 0.0113\n",
      "epoch=9, batch=300 loss: 0.0124\n",
      "epoch=9, batch=400 loss: 0.0146\n",
      "epoch=9 accuracy=97.00%\n",
      "epoch=10, batch=100 loss: 0.0106\n",
      "epoch=10, batch=200 loss: 0.0115\n",
      "epoch=10, batch=300 loss: 0.0145\n",
      "epoch=10, batch=400 loss: 0.0135\n",
      "epoch=10 accuracy=97.00%\n",
      "epoch=11, batch=100 loss: 0.0078\n",
      "epoch=11, batch=200 loss: 0.0089\n",
      "epoch=11, batch=300 loss: 0.0117\n",
      "epoch=11, batch=400 loss: 0.0122\n",
      "epoch=11 accuracy=97.00%\n",
      "epoch=12, batch=100 loss: 0.0078\n",
      "epoch=12, batch=200 loss: 0.0067\n",
      "epoch=12, batch=300 loss: 0.0089\n",
      "epoch=12, batch=400 loss: 0.0121\n",
      "epoch=12 accuracy=97.00%\n",
      "epoch=13, batch=100 loss: 0.0078\n",
      "epoch=13, batch=200 loss: 0.0077\n",
      "epoch=13, batch=300 loss: 0.0074\n",
      "epoch=13, batch=400 loss: 0.0087\n",
      "epoch=13 accuracy=97.00%\n",
      "epoch=14, batch=100 loss: 0.0076\n",
      "epoch=14, batch=200 loss: 0.0078\n",
      "epoch=14, batch=300 loss: 0.0057\n",
      "epoch=14, batch=400 loss: 0.0050\n",
      "epoch=14 accuracy=97.00%\n",
      "epoch=15, batch=100 loss: 0.0049\n",
      "epoch=15, batch=200 loss: 0.0049\n",
      "epoch=15, batch=300 loss: 0.0073\n",
      "epoch=15, batch=400 loss: 0.0082\n",
      "epoch=15 accuracy=97.00%\n",
      "epoch=16, batch=100 loss: 0.0064\n",
      "epoch=16, batch=200 loss: 0.0076\n",
      "epoch=16, batch=300 loss: 0.0084\n",
      "epoch=16, batch=400 loss: 0.0069\n",
      "epoch=16 accuracy=97.00%\n",
      "epoch=17, batch=100 loss: 0.0070\n",
      "epoch=17, batch=200 loss: 0.0064\n",
      "epoch=17, batch=300 loss: 0.0085\n",
      "epoch=17, batch=400 loss: 0.0105\n",
      "epoch=17 accuracy=97.00%\n",
      "epoch=18, batch=100 loss: 0.0073\n",
      "epoch=18, batch=200 loss: 0.0058\n",
      "epoch=18, batch=300 loss: 0.0058\n",
      "epoch=18, batch=400 loss: 0.0042\n",
      "epoch=18 accuracy=97.00%\n",
      "epoch=19, batch=100 loss: 0.0046\n",
      "epoch=19, batch=200 loss: 0.0032\n",
      "epoch=19, batch=300 loss: 0.0033\n",
      "epoch=19, batch=400 loss: 0.0033\n",
      "epoch=19 accuracy=98.00%\n",
      "epoch=20, batch=100 loss: 0.0035\n",
      "epoch=20, batch=200 loss: 0.0049\n",
      "epoch=20, batch=300 loss: 0.0040\n",
      "epoch=20, batch=400 loss: 0.0042\n",
      "epoch=20 accuracy=97.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data.dataloader as Data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    " 'dataset/mnist-pytorch', train=True, \n",
    "    transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])]),\n",
    "    download=True\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    " 'dataset/mnist-pytorch', train=False, \n",
    "    transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
    ")\n",
    "print(\"train_data:\", train_data.train_data.size())\n",
    "print(\"train_labels:\", train_data.train_labels.size())\n",
    "print(\"test_data:\", test_data.test_data.size())\n",
    "\n",
    "#批大小\n",
    "batch_size=128\n",
    "#训练的批次数\n",
    "epochs=20\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x=self.dense(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "def main():\n",
    "\n",
    "    # 自适应使用GPU还是CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = Net().to(device)\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 每训练100个batch打印一次平均loss\n",
    "            sum_loss += loss.item()\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('epoch=%d, batch=%d loss: %.04f'\n",
    "                      % (epoch + 1, i+1, sum_loss / 100))\n",
    "                sum_loss = 0.0\n",
    "        # 每跑完一次epoch测试一下准确率 进入测试模式 禁止梯度传递\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in test_loader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                # 取得分最高的那个类\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('epoch=%d accuracy=%.02f%%' % (epoch + 1, (100 * correct / total)))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
